{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfa15fa",
   "metadata": {},
   "source": [
    "# 上下文压缩技术\n",
    "过滤并压缩检索到的文本块，减少噪声从而提高响应质量，主要作用其实是在检索到的块内删掉无关的句子和段落，也就是chunk内过滤，在上下文窗口中最大化有用信号。\n",
    "\n",
    "\n",
    "主要使用三种方法：\n",
    "1. 过滤：分析文档块并仅提取与用户查询直接相关的句子或段落，移除所有无关内容。\n",
    "2. 摘要：创建文档块的简洁摘要，且仅聚焦与用户查询相关的信息。\n",
    "3. 抽取：从文档块中精确提取与用户查询相关的完整句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0b8ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.issues\\\\server'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from zhipuai import ZhipuAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "issues_dir = \".issues\"\n",
    "json_name = \"server\"\n",
    "json_path = os.path.join(issues_dir,json_name)\n",
    "json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12592683",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../AI_Information.en.zh-CN.pdf\"\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "client = ZhipuAI(api_key  = API_KEY)\n",
    "\n",
    "llm_model = os.getenv(\"llm_model\")\n",
    "embedding_model = os.getenv(\"embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e6f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d3cab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf_2(pdf_path):\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串以存储提取的文本\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]\n",
    "        text = page.get_text(\"text\")  # 从页面中提取文本\n",
    "        all_text += text  # 将提取的文本追加到 all_text 字符串中\n",
    "\n",
    "    return all_text  # 返回提取的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_pdf = extract_text_from_pdf(pdf_path)\n",
    "#print(read_pdf[:5000])  # 打印前5000个字符以检查内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2656ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    chunks = []\n",
    "\n",
    "    chunks = []  \n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        chunk = text[i:i + n]\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = \"出一款刚配置的台式机，很新，在南京线下实体店刚配的，后面去外地实习用不到了。4060显卡 12400kf.  内存16✖️2   1t固态，多个风扇，黑色海景房，打游戏仿真都绰绰有余。预计价格在4200，非诚勿扰，诚心要的可加v:daji705 。可具体看配置信息\"\n",
    "chunks = chunk_text(demo, 10, 6)\n",
    "print(\"分割后的文本块:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"块 {i + 1}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0562b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    使用 NumPy 实现的轻量级向量存储，包括原始文本、嵌入向量、元数据。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectors = [] # 存储嵌入向量\n",
    "        self.texts = [] # 存储对应的原始文本块\n",
    "        self.metadata = [] # 存储对应的元数据\n",
    "\n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        向向量存储中添加一个项目。\n",
    "\n",
    "        Args:\n",
    "        text (str): 原始文本。\n",
    "        embedding (List[float]): 嵌入向量。\n",
    "        metadata (dict, 可选): 额外的元数据。\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))\n",
    "        self.texts.append(text)\n",
    "        # self.metadata.append(metadata if metadata is not None else {})\n",
    "        self.metadata.append(metadata or {})\n",
    "\n",
    "    def similarity_search(self, query_embedding, top_k=5):\n",
    "        \"\"\"\n",
    "        查找与查询嵌入最相似的项目。\n",
    "\n",
    "        Args:\n",
    "        query_embedding (List[float]): 查询嵌入向量。\n",
    "        k (int): 返回的结果数量。\n",
    "\n",
    "        Returns:\n",
    "        List[Dict]: 包含文本和元数据的前k个最相似项。\n",
    "        \"\"\"\n",
    "        # 存储向量为空\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "        query_vector = np.array(query_embedding)\n",
    "\n",
    "        #计算余弦相似度\n",
    "        similarities = []\n",
    "        for i,vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(query_vector, vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i, similarity)) # 加入索引、相似度元组\n",
    "\n",
    "        # 按相似度降序排序\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        results = []\n",
    "        for i in range(min(top_k, len(similarities))):\n",
    "            index, similarity = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[index],\n",
    "                \"similarity\": similarity,\n",
    "                \"metadata\": self.metadata[index]\n",
    "            })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1caee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text):\n",
    "    \"\"\"\n",
    "    使用Embedding模型为给定文本创建嵌入向量。\n",
    "\n",
    "    Args:\n",
    "        text (str): 要创建嵌入向量的输入文本。\n",
    "\n",
    "    Returns:\n",
    "        List[float]: 嵌入向量。\n",
    "    \"\"\"\n",
    "    # 将输入转换为列表来处理字符串\n",
    "    input_text = text if isinstance(text, list) else [text]\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=embedding_model,  \n",
    "        input=input_text\n",
    "    )\n",
    "\n",
    "    if isinstance(text,str):\n",
    "        return response.data[0].embedding\n",
    "    \n",
    "    return [item.embedding for item in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f29c10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path,chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    为RAG处理文档。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文件的路径。\n",
    "        chunk_size (int): 每个文本块的大小（以字符为单位）。\n",
    "        chunk_overlap (int): 文本块之间的重叠大小（以字符为单位）。\n",
    "\n",
    "    Returns:\n",
    "        SimpleVectorStore: 包含文档文本块及其嵌入向量的向量存储。\n",
    "    \"\"\"\n",
    "    # 提取、分割、嵌入\n",
    "    print(\"提取pdf文本...\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"分割文本块...\")\n",
    "    chunks = chunk_text(text, chunk_size, chunk_overlap)\n",
    "    print(f\"总共分割为 {len(chunks)} 个文本块。\")\n",
    "\n",
    "    print(\"创建嵌入向量...\")\n",
    "    chunk_embeddings = create_embeddings(chunks)\n",
    "    \n",
    "    # 创建向量存储，存入文本块、嵌入向量和元数据\n",
    "    vector_store = SimpleVectorStore()\n",
    "\n",
    "    for i,(chunk, embedding) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "        metadata = {\n",
    "            \"index\": i,\n",
    "            \"source\": pdf_path\n",
    "        }\n",
    "        vector_store.add_item(chunk, embedding, metadata)\n",
    "    \n",
    "    print(f\"向向量存储中添加了 {len(chunks)} 个文本块\")\n",
    "    return vector_store\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8347c0c",
   "metadata": {},
   "source": [
    "至此，process_document已经完成了基础的pdf的文档处理，包括提取、分块、嵌入向量、向量存储\n",
    "下面实现上下文压缩的核心部分：过滤、压缩检索内容\n",
    "\n",
    "# 上下文压缩by llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2214cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_chunk(chunk,query,compression_type=\"selective\"):\n",
    "    \"\"\"\n",
    "    压缩检索到的文本块，仅保留与查询相关的内容。query是压缩检索的依据\n",
    "\n",
    "    Args:\n",
    "        chunk (str): 要压缩的文本块\n",
    "        query (str): 用户查询\n",
    "        compression_type (str): 压缩类型 (\"selective\", \"summary\" 或 \"extraction\")\n",
    "\n",
    "    Returns:\n",
    "        str: 压缩后的文本块\n",
    "    \"\"\"\n",
    "\n",
    "    # 为不同的压缩方法定义系统提示\n",
    "    if compression_type == \"selective\":\n",
    "        system_prompt = \"\"\"您是专业信息过滤专家。\n",
    "        您的任务是分析文档块并仅提取与用户查询直接相关的句子或段落，移除所有无关内容。\n",
    "\n",
    "        输出要求：\n",
    "        1. 仅保留有助于回答查询的文本\n",
    "        2. 保持相关句子的原始措辞（禁止改写）\n",
    "        3. 维持文本的原始顺序\n",
    "        4. 包含所有相关文本（即使存在重复）\n",
    "        5. 排除任何与查询无关的文本\n",
    "\n",
    "        请以纯文本格式输出，不添加任何注释。\"\"\"\n",
    "\n",
    "    elif compression_type == \"summary\":\n",
    "        system_prompt = \"\"\"您是专业摘要生成专家。\n",
    "        您的任务是创建文档块的简洁摘要，且仅聚焦与用户查询相关的信息。\n",
    "\n",
    "        输出要求：\n",
    "        1. 保持简明扼要但涵盖所有相关要素\n",
    "        2. 仅聚焦与查询直接相关的信息\n",
    "        3. 省略无关细节\n",
    "        4. 使用中立、客观的陈述语气\n",
    "\n",
    "        请以纯文本格式输出，不添加任何注释。\"\"\"\n",
    "\n",
    "    else:  # extraction\n",
    "        system_prompt = \"\"\"您是精准信息提取专家。\n",
    "        您的任务是从文档块中精确提取与用户查询相关的完整句子。\n",
    "\n",
    "        输出要求：\n",
    "        1. 仅包含原始文本中的直接引用\n",
    "        2. 严格保持原始文本的措辞（禁止修改）\n",
    "        3. 仅选择与查询直接相关的完整句子\n",
    "        4. 不同句子使用换行符分隔\n",
    "        5. 不添加任何解释性文字\n",
    "\n",
    "        请以纯文本格式输出，不添加任何注释。\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        查询: {query}\n",
    "\n",
    "        文档块:\n",
    "        {chunk}\n",
    "\n",
    "        请严格提取与本查询相关的文档块的核心内容。\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\": system_prompt},\n",
    "            {\"role\":\"user\",\"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    # 从响应中提取压缩后的文本块（str）\n",
    "    compressed_chunk = response.choices[0].message.content.strip()\n",
    "\n",
    "    # 计算压缩比率\n",
    "    original_length = len(chunk)\n",
    "    compressed_length = len(compressed_chunk)\n",
    "    compression_ratio = (original_length - compressed_length) / original_length * 100\n",
    "\n",
    "    return compressed_chunk, compression_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1ff40",
   "metadata": {},
   "source": [
    "# 批量压缩\n",
    "一次性压缩多个文本块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa5e3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_compress_chunks(chunks,query,compression_type=\"selective\"):\n",
    "    \"\"\"\n",
    "    逐个压缩多个文本块。\n",
    "\n",
    "    Args:\n",
    "        chunks (List[str]): 要压缩的文本块列表\n",
    "        query (str): 用户查询\n",
    "        compression_type (str): 压缩类型 (\"selective\", \"summary\", 或 \"extraction\")\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: 包含压缩比率的压缩文本块列表\n",
    "    \"\"\"\n",
    "    print(f\"正在压缩 {len(chunks)} 个文本块...\")\n",
    "    results = []\n",
    "    sum_original_length = 0\n",
    "    sum_compressed_length = 0\n",
    "\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        print(f\"正在压缩文本块 {i+1}/{len(chunks)}...\")\n",
    "        compressed_chunk,compression_ratio = compress_chunk(chunk, query, compression_type)\n",
    "        results.append((compressed_chunk, compression_ratio))\n",
    "\n",
    "        sum_original_length += len(chunk)\n",
    "        sum_compressed_length += len(compressed_chunk)\n",
    "\n",
    "    # 计算总压缩比率\n",
    "    total_compression_ratio = (sum_original_length - sum_compressed_length) / sum_original_length * 100\n",
    "    print(f\"总体压缩比率: {total_compression_ratio:.2f}%\")\n",
    "\n",
    "    return results # 返回包含压缩文本块和压缩比率的列表\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be621243",
   "metadata": {},
   "source": [
    "# 回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "466191a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query,context):\n",
    "    \"\"\"\n",
    "    根据查询和上下文生成响应。\n",
    "\n",
    "    Args:\n",
    "        query (str): 用户查询\n",
    "        context (str): 从压缩块中提取的上下文文本，也就是compressed_chunk\n",
    "\n",
    "    Returns:\n",
    "        str: 生成的响应\n",
    "    \"\"\"\n",
    "    # 定义系统提示以指导AI的行为\n",
    "    system_prompt = \"您是一个乐于助人的AI助手。请仅根据提供的上下文来回答用户的问题。如果在上下文中找不到答案，请直接说'没有足够的信息'。\"\n",
    "\n",
    "    # 通过组合上下文和查询创建用户提示\n",
    "    user_prompt = f\"\"\"\n",
    "        上下文:\n",
    "        {context}\n",
    "\n",
    "        问题: {query}\n",
    "\n",
    "        请基于上述上下文内容提供一个全面详尽的答案。\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,    \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],          \n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2221062",
   "metadata": {},
   "source": [
    "# 上下文压缩的完整RAG执行管道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0e961e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_compression(pdf_path,query,k=10,compression_type=\"selective\"):\n",
    "    \"\"\"\n",
    "    完整的RAG管道，包含上下文压缩。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文档的路径\n",
    "        query (str): 用户查询\n",
    "        k (int): 初始检索的块数量\n",
    "        compression_type (str): 压缩类型\n",
    "\n",
    "    Returns:\n",
    "        dict: 包括查询、压缩块和响应的结果\n",
    "    \"\"\"\n",
    "    print(\"\\n=== RAG WITH CONTEXTUAL COMPRESSION ===\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Compression type: {compression_type}\")\n",
    "\n",
    "    # 1. 处理文档，完成文档的提取、分块、创建嵌入向量\n",
    "    vector_store = process_document(pdf_path)\n",
    "\n",
    "    # 2. 创建 查询 嵌入向量\n",
    "    query_embedding = create_embeddings(query)\n",
    "    \n",
    "    # 3. 检索与查询最相关的k个文本块\n",
    "    print(f\"Retrieving top {k} chunks...\")\n",
    "    results = vector_store.similarity_search(query_embedding, top_k=k)\n",
    "    #    提取检索到的文本块,results是一个list，三元组\n",
    "    retrieved_chunks = [result[\"text\"] for result in results]\n",
    "\n",
    "    # 4. 压缩检索到的文本块\n",
    "    compressed_results = batch_compress_chunks(retrieved_chunks, query, compression_type)\n",
    "    #batch_compress_chunks返回compressed_results是（chunk，ratio）\n",
    "    compressed_chunks = [result[0] for result in compressed_results]\n",
    "    compression_ratios = [result[1] for result in compressed_results]\n",
    "\n",
    "    # 过滤掉空的块\n",
    "    filtered_chunks = [(chunk,ratio) for chunk, ratio in zip(compressed_chunks, compression_ratios) if chunk.strip]\n",
    "\n",
    "    # 如果过滤后都为空，使用原始块\n",
    "    if not filtered_chunks:\n",
    "        print(\"所有块都被压缩为空，使用原始块。\")\n",
    "        filtered_chunks = [(chunk, 0) for chunk in retrieved_chunks]\n",
    "    else:\n",
    "        compressed_chunks, compression_ratios = zip(*filtered_chunks)\n",
    "\n",
    "    # 5. 将压缩后的块合并为一个上下文字符串\n",
    "    context = \"\\n\\n\".join(compressed_chunks)  # 将压缩后的块合并为一个上下文字符串\n",
    "\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # 6. 返回结果字典\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"original_retrieved_chunks\": retrieved_chunks,\n",
    "        \"compressed_chunks\": compressed_chunks,\n",
    "        \"compressed_ratios\": compression_ratios,\n",
    "        \"context_length_reduction\": f\"{sum(compression_ratios)/len(compression_ratios):.2f}%\",\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== RAG RESULT ===\")\n",
    "    print(f\"Response: {response}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9ece03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
      "Query: 如何评价人工智能对人类的影响?\n",
      "Compression type: selective\n",
      "提取pdf文本...\n",
      "分割文本块...\n",
      "总共分割为 13 个文本块。\n",
      "创建嵌入向量...\n",
      "向向量存储中添加了 13 个文本块\n",
      "Retrieving top 10 chunks...\n",
      "正在压缩 10 个文本块...\n",
      "正在压缩文本块 1/10...\n",
      "正在压缩文本块 2/10...\n",
      "正在压缩文本块 3/10...\n",
      "正在压缩文本块 4/10...\n",
      "正在压缩文本块 5/10...\n",
      "正在压缩文本块 6/10...\n",
      "正在压缩文本块 7/10...\n",
      "正在压缩文本块 8/10...\n",
      "正在压缩文本块 9/10...\n",
      "正在压缩文本块 10/10...\n",
      "总体压缩比率: 59.30%\n",
      "\n",
      "=== RAG RESULT ===\n",
      "Response: 人工智能对人类的影响是深远和多方面的，既有积极的一面，也存在需要关注和解决的挑战。\n",
      "\n",
      "积极影响方面：\n",
      "1. 提高效率：人工智能通过自动化日常任务和优化工作流程，在各个行业中提高了生产效率和服务质量。\n",
      "2. 创新和创造力：人工智能在艺术、音乐、写作等领域的应用为人类提供了全新的创作工具，激发了新的艺术形式和表达方式。\n",
      "3. 医疗保健：人工智能在医疗诊断、治疗和药物研发方面的应用，提高了诊断的准确性，加速了新药的发现，实现了更个性化的医疗服务。\n",
      "4. 城市规划和环境保护：人工智能在智慧城市建设中的应用，如交通系统优化、能源管理改善和环境监测，有助于提升城市运营效率，减少资源浪费，保护环境。\n",
      "5. 教育个性化：人工智能可以根据每个学生的学习需求和风格提供个性化教育，提高学习效果。\n",
      "6. 支持决策：人工智能通过分析大量数据，为人类决策提供洞察，增强了决策的科学性和有效性。\n",
      "\n",
      "挑战和潜在负面影响：\n",
      "1. 工作岗位流失：人工智能自动化可能导致某些行业的工作岗位减少，特别是那些重复性和低技能的工作。\n",
      "2. 伦理和偏见问题：如果人工智能系统设计不当，可能会继承并放大训练数据中的偏见，导致不公平和歧视性的结果。\n",
      "3. 隐私和安全：人工智能系统通常依赖大量数据，这可能引发隐私泄露的风险，同时，人工智能的安全问题也可能带来安全隐患。\n",
      "4. 透明度和可解释性：一些人工智能系统缺乏透明度，难以解释其决策过程，这可能会影响公众对人工智能的信任。\n",
      "5. 伦理监管：需要建立有效的伦理监管框架来确保人工智能的负责任使用，防止其被滥用。\n",
      "\n",
      "综上所述，人工智能对人类社会的影响是双刃剑。为了最大限度地发挥其积极影响，同时减少潜在的负面影响，需要全球范围内的合作，制定合理的政策和伦理指导原则，加强人工智能的透明度和可解释性，以及通过教育和培训帮助劳动力适应新的工作环境。此外，确保人工智能系统的公平性、安全性和隐私保护是当前和未来发展的关键。\n"
     ]
    }
   ],
   "source": [
    "query = \"如何评价人工智能对人类的影响?\"\n",
    "result = rag_with_compression(pdf_path, query, k=10, compression_type=\"selective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b1330",
   "metadata": {},
   "source": [
    "# 与标准RAG性能对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_rag(pdf_path,query,k=10):\n",
    "    \"\"\"\n",
    "    标准RAG，不包含压缩。\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): PDF文档的路径\n",
    "        query (str): 用户查询\n",
    "        k (int): 检索的块数量\n",
    "\n",
    "    Returns:\n",
    "        dict: 包括查询、块和响应的结果\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
