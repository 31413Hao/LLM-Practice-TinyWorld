{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c670f2",
   "metadata": {},
   "source": [
    "### 配置Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "102192ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY: f532b4bd71324c1ca2fd7e22d4eb41da.4Sfpr8wE6qEVV5BY\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "#示例：langgraph_hello.py\n",
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "# pip install langgraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "print(\"API_KEY:\", API_KEY)\n",
    "\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "# 创建智谱AI LLM实例\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "print(llm.openai_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b058650",
   "metadata": {},
   "source": [
    "#### 提示词模板、输出转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f458a663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'春风拂面花千树，\\n燕舞蓝天梦无边。\\n美好时光手中握，\\n共享人间四月天。'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个有帮助的助手。\"),\n",
    "    (\"user\", \"请根据以下内容回答问题：{input}\"),\n",
    "])\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "chain.invoke({\"input\": \"生成一个20字左右的小诗歌\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6527d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个关于浙江大学软件学院的冷笑话，要求笑话内容不超过50字，只能由你来原创，不能抄已有的。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'浙软学子编程强，\\n写出代码无人详，\\n问其原因何其长？\\n答曰：我是浙大软件人，代码自己会解释。'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_jokes = ChatPromptTemplate.from_template(\n",
    "    \"给我讲一个关于{topic}的{style}笑话，要求笑话内容不超过50字，只能由你来原创，不能抄已有的。\"\n",
    ")\n",
    "\n",
    "\n",
    "result = prompt_template_jokes.format_messages(topic=\"浙江大学软件学院\", style=\"冷\")\n",
    "print(result[0].content)\n",
    "chain.invoke(result[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e765cbc",
   "metadata": {},
   "source": [
    "#### 工作流LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f78b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b01882",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"搜索工具\"\"\"\n",
    "    return f\"搜索结果：关于{query}的回答是...（模拟搜索结果）\"\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# bind_tools方法将工具绑定到ToolNode\n",
    "model = llm.bind_tools(tools)\n",
    "\n",
    "# 是否继续，只允许返回\"tools\"或END\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    \"\"\"判断是否继续\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # 如果llm调用了工具，就转到工具节点\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # 否则结束，回复用户\n",
    "    return END\n",
    "\n",
    "# 调用函数\n",
    "def call_model(state:MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    # 返回一个消息列表，用于添加到消息列表中\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 初始化状态图，定义一个新的状态图\n",
    "workflow= StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"agent\",call_model) \n",
    "workflow.add_node(\"tools\", tool_node) \n",
    "\n",
    "workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
